{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fc605d-2451-4a3a-bb8b-b645aa70fcb5",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e97860c-431a-4b99-b43f-6a9554b48d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments\n",
    "from training import compute_metrics1, CustomTrainer\n",
    "from inference import infer, highlight_words\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12477634-8fef-42e4-a798-efec0967b68c",
   "metadata": {},
   "source": [
    "# Load the test dataset and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36041d33-21ef-47e4-a5ed-24f71e6fd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaded = load_from_disk('./data/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2236acb9-9c23-421d-9e60-3d0b02349484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1190ce2eff43daad1f87d97811223e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f615d7f68e447a9b29c52aafd8fb3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae2fdb77f5a4e7092d7a28ad59aadf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ba3bca2ee24d0390d804636318d1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447c88e2792d46da9e0ddc08594639aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc3010ac92e4e358d586934e2e66ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('huggingsaurusRex/bert-base-uncased-for-mountain-ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained('huggingsaurusRex/bert-base-uncased-for-mountain-ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2906f183-98a0-475a-9f62-51817a218162",
   "metadata": {},
   "source": [
    "Perform the dataset preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01303b63-193c-409a-9cab-ec2cb45ab53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"\n",
    "    convert labeled words to labeled tokens\n",
    "    :param labels: word labels\n",
    "    :param word_ids: list of word ids for each token\n",
    "    :return: token labels\n",
    "    \"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # a new word\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # special token, typically set to -100\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # same word as previous token\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    tokenize the samples and align the labels\n",
    "    :param examples: dataset samples\n",
    "    :return: tokenized samples\n",
    "    \"\"\"\n",
    "    # apply tokenizer to the tokens\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"fine_ner_tags\"]\n",
    "    new_labels = []\n",
    "    # for each sentence in the dataset align the labels for tokens\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc9041cb-03ab-4c13-af4f-86733c192540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fbe00d08c04f12af9c7280e6c90999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/886 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_test = test_loaded.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5864553-dc27-4b7c-9475-1e48ffaed4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e309658-baf9-49c2-86f7-87bf5e74b5d2",
   "metadata": {},
   "source": [
    "Prepare for testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b59007c5-b45d-4559-8b82-90dca5d8df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./models/logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "970c8563-2632-4dae-878d-0536fe6868bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"./models/logs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics1,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916ea37-edea-45b1-831d-defb54b14431",
   "metadata": {},
   "source": [
    "# Test the model on test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2c3a2df-2625-4dd5-90a0-1a1b227df13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111/111 02:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute model's scores on test split\n",
    "test_scores = trainer.evaluate(eval_dataset=tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "051bbf25-1331-40f8-88a0-11f46869c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.835233541743288\n",
      "Recall = 0.9051414906337186\n",
      "F1-score = 0.8687834736036726\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision = {test_scores[\"eval_precision_class1\"]}')\n",
    "print(f'Recall = {test_scores[\"eval_recall_class1\"]}')\n",
    "print(f'F1-score = {test_scores[\"eval_f1_class1\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39312cce-1743-4c0f-a6f4-489bcb59efea",
   "metadata": {},
   "source": [
    "# Test the model on sample data (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7fb917d-8c06-45e3-89b3-145907dc50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample text and put it into 'sample1.txt'\n",
    "sample_text = \"I spent days climbing the Mount Evelest.\\nI founded a company called 'Everest'.\"\n",
    "with open('sample1.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dae65a9a-96c6-42c9-a34f-74e0a9505b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference\n",
    "content, word_labels, highlights = infer(model, tokenizer, 'sample1.txt')\n",
    "# put the results into 'sample1_pred.txt' neatly\n",
    "highlight_words(content, 'sample1_pred.txt', highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "308dcf6e-88c4-477f-9c3c-e23d1cd64d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I spent days climbing the <mountain>Mount</mountain> <mountain>Evelest</mountain>.\n",
      "I founded a company called 'Everest'.\n"
     ]
    }
   ],
   "source": [
    "with open('sample1_pred.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc6d7e-56dc-40ae-86be-399484ac55ed",
   "metadata": {},
   "source": [
    "As we can see, the model differentiates between a company Everest, and the mount Everest.\n",
    "Also, the typo in word Everest did not confuse it.\n",
    "\n",
    "Let's look at another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8aaf057e-1e1a-46c3-83cf-99829dab97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample text and put it into 'sample2.txt'\n",
    "sample_text = \"The tallest mountains in the Alps include: Mont Blanc, Piz Bernina, the Dom, the Grand Combin, and others.\"\n",
    "with open('sample2.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07f3de7d-b6a5-46bf-9019-328e0cab1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inference\n",
    "content, word_labels, highlights = infer(model, tokenizer, 'sample2.txt')\n",
    "# put the results into 'sample1_pred.txt' neatly\n",
    "highlight_words(content, 'sample2_pred.txt', highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9a2dc5b-3f54-434c-8842-3173d709cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tallest mountains in <mountain>the</mountain> <mountain>Alps</mountain> include: <mountain>Mont</mountain> <mountain>Blanc</mountain>, <mountain>Piz</mountain> <mountain>Bernina</mountain>, the <mountain>Dom</mountain>, the <mountain>Grand</mountain> <mountain>Combin</mountain>, and others.\n"
     ]
    }
   ],
   "source": [
    "with open('sample2_pred.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008da5f9-0917-41ea-aa73-d681de12ee31",
   "metadata": {},
   "source": [
    "This example demonstrates that the model sometimes considers article 'the' as a mountain, like in the Alps. But it was not confused by a lot of compound mountain names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db053271-3104-45bf-a1f9-c53ec503f623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
